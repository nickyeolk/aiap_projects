{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Week 2\n",
    "Last week you played with data and built models in a very practical way. This week, you will go deeper into theory and spend time on some foundational concepts.  This notebook is divided into two sections:\n",
    "\n",
    "1. The Theory: an introduction to bias and variance - two key concepts in machine learning - and how they affect model performance\n",
    "2. The Practice: a chance for you to experiment with how we deal with these concepts in practice\n",
    "\n",
    "**You may finish the coding questions fairly quickly, but we expect you to spend most of your time teaching yourself the theoretical concepts** that come up in this notebook. We will use the 2-on-1 review session to test you on these concepts. Consequently, you should spend your time going through the below **resources** and playing with these concepts beyond this notebook.\n",
    "### Resources (spend your time here!)\n",
    "- [Caltech Learn from data](http://work.caltech.edu/telecourse.html \"\"): Seminal online course that introduces the theory of machine learning\n",
    "- [Introduction to Statistical Learning](https://www-bcf.usc.edu/~gareth/ISL/ \"\"): Landmark textbook (and videos) on machine learning theory\n",
    "- *Machine Learning* by Tom M. Mitchell: See chapters 5.2 & 5.3 (textbook available on our bookshelf)\n",
    "- [Datacamp Supervised learning with scikit-learn](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn \"\"): Practical walkthrough of some key concepts and their application\n",
    "- [Understanding the Bias Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html \"\"): Blog post on the topic of bias and variance\n",
    "- [Kaggle Ensembling Guide](https://mlwave.com/kaggle-ensembling-guide/ \"\"): Ensembling guide\n",
    "- [XGBoost tutorials](https://xgboost.readthedocs.io/en/latest/tutorials/model.html \"\"): XGBoost guide\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Collaboration is the best way to learn. Try everything yourself first, then discuss your method with your teammates. Do not directly copy their code, unless you are trying to learn a programming technique. Do your own thinking and write your own code.\n",
    "\n",
    "If you believe referring to someone's answer is the best way to learn, we recommend looking at the code, then walking away for a few minutes, and come back to write your own version of the code. There will be minimum policing, but we will check for direct copying of code.\n",
    "\n",
    "Please list your collaborators:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tupac Shakur\n",
    "2. ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "This section should be reserved for packages/libraries you that you would normally use (you can add models/functions/libraries as you go along)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Begin by loading the Boston House Prices dataset, or simply the Boston dataset, for our exploration. <br>\n",
    "You can find it on Kaggle, or simply import it from the scikit-learn build-in datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Theoretical Side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first week, you learned about how to use some supervised learning algorithms. In this second week, we will go slightly deeper, to appreciate why machine learning works. We still stay in the realm of supervised learning, but many of the concepts learned here are applicable to general machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to demonstrate the impact of implementing complicated models. <br> __Explore the dataset and choose one variable that you think can be most predictive of the target variable (price) in the Boston dataset.__ <br> (Please provide justification to the variable you chose in writing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your verbal answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a linear regression model, and try to predict the price based on the parameter you chose:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extract the coefficients or weights of the linear model interpret what they mean.__ <br> Make sure you visualise the linear regression line and comment on how the line fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your verbal answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is considered a simple model, using a polynomial model introduces a higher complexity. <br>\n",
    "__Find and implement two more models (with medium and high complexity) to predict the target variable, using the same variable you chose for the previous part__ (Be sure to visualize your result and comment about the fit).\n",
    "\n",
    "Fit and plot your medium complexity model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and plot your high complexity model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following section to answer: which of the models has the best fit and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find a quantitative way of measuring the model fit__ <br>\n",
    "Calculate it for each one of the models and compare the results to your visual inspection interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did the exercise right, you should see the viaual and quantative fit increase in the same direction as the model complexity. \n",
    "\n",
    "\n",
    "##### But is fitness a good measure of a model?\n",
    "In order to put this question to the test, __perform a cross-validation test for the three models and compare between them:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What measure did you use to compare between the models and why? <br>\n",
    "Which one fits the data the best? Explain that result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to extend this discussion by including all the remaining variables in the Boston dataset. <br> __Fit the three models, use _all_ the variables in the Boston dataset and compare their cross validation scores.__ <br> See if you observe the same patterns as when using one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each model, explain the differences you encountered when expanding the dataset.<br>\n",
    "- Compare the current result between models and try to explain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Share your thoughts/conclusions regarding complexity in modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Expending our discussion on model complexity, comment below how one can decrease/increase complexity in the following families of algorithms:__ \n",
    "- Decision tree \n",
    "- Artificial neural network \n",
    "- Support vector machine\n",
    "- K-nearest neighbour\n",
    "- Bayesian method (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Provide the best explanation/definition (using your own words) of over/under-fitting:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bias Variance Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might claim machine learning is about balancing. If that's the case, what measure can we use to find the right balance? \n",
    "\n",
    "From a more theoretical perspective, two useful measures are bias and variance.<br>\n",
    "In an intuitive sense, __bias__ is how off-the-mark our prediction/estimate tends to be with respect to the true value we are trying to predict. Usually we get bias because of inherent limitation in the model/algorithm we choose, for example linear regression is limited only to fit linear patterns, and hence \"biased\" towards linearity. <br>\n",
    "__Variance__ is how flexible the predictions made by the model can be to fit more complicated patterns in data. Highly complex models tend to have high variance. This comes as a cost; as flexibility increases, the sensitivity of the models to the training data that they try to fit increases, resulting in the predictions being more distributed away from the true values. \n",
    "\n",
    "__This is just the tip of the iceberg, we encourage you to pause your work on the notebook for now and seek more information about the relationship to get a better understanding before we dive in.__\n",
    "\n",
    "Bias and variance is a trade-off, increasing one decreases the other.<br> __Provide an explanation to why this is so:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Provide mathematical formulas for the bias, the variance and the overall prediction error of a model:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting our focus to a more practical approach, we will now try and demonstrate how to find the right balance between bias variance when fitting a model. \n",
    "\n",
    "__Define a high order polynomial curve to fit:__ <br>\n",
    "(One example is: $f(x)=0.2x^{5}-3.5x^{4}+21x^{3}-53x^{2}+37x+0.6$ (you are free to define another function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the function you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to estimate this function using polynomial regression. In real-life cases, the true function is not accessible to us, only noisy estimates around it.\n",
    "\n",
    "__Now, simulate a training data by introducing random errors on the curve.__<br>The training data should look like the figure below (make sure you have at least a 1000 observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./training_data.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spare a few hundreds samples to use as the validation set (and plot it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the remaining data, build 500 linear regression models, each by randomly sampling 80 observations from the pool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculate the bias square and variance of linear regression by predicting (using the 500 models) the values of the validation set above, and comparing them against the true values from the polynomial curve defined earlier.__ <br> (refer to the bias variance formula to do the calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the whole procedure of calculating bias variance, but this time using polynomial of degrees 2, 3, 4, ..., 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the bias and variance (as y) vs. the model complexity/polynomial degree (as x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the optimal balance point? Which polynomial degree is that? <br>\n",
    "Find out more and elaborate on the meaning and importance that point of balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Practical Side "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias-variance trade-off is one of the most critical components of model tuning. You will need to find the right point in terms of model complexity to derive the best results for your model.\n",
    "\n",
    "In practice, however, it is impossible to calculate bias and variance for an actual dataset. Try to explain why this is impossible below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the procedure you used to calculate bias-variance above, but this time calculate mean squared error instead. <br> Overlay the MSE on the bias variance plot earlier and comment on the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Provide your answer here)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Out-of-sample Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we will go back to using mean squared errors (MSE) to tune our models. In reality, validation error is the most reliable source of information you can get, provided you do validation properly. You might have realised that MSE scores are negative when you put them through the `cross_val_score` method - do think about why this is so as well.\n",
    "\n",
    "If you would like to do any data exploration, you can do them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by building simple baseline models for our dataset. We will start with 3 baseline models: linear regression, k-nearest neighbours and decision trees. Build a simple regression model for each of them. Evaluate and report their performance, and identify the best model by preliminary performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we ensure that our models are reliably evaluated? Specifically, in the area of out-of-sample validation, how do we decide to use `train_test_split` vs `cross_val_score`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the dataset has only ~500 rows of data, what are the challenges we face, and how can we best mitigate these issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start to look at hyperparameters for these models. Considering between the 3 models, k-nearest neighbours probably has the least hyperparameters to tune, and is also the simplest computationally. Hence, let's start with k-nearest neighbours. You might not want to try all of these parameters, considering limited time. This is a good time to do some research with respect to what parameters to optimise.\n",
    "\n",
    "When conducting a parameter search, the idea of grid search immediately comes to mind. Why do we usually use grid search, and in what situations should we use other search options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we not use gradient descent to identify the right parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': 1,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors.KNeighborsRegressor().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the `n_neighbors` and `n_jobs` parameters, pick out 1-2 more which you are unfamiliar with and do some research. Explain what they do with language intended for a lay person. You may also wish to spend some time thinking about how you might want to implement such a model algorithmically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to a more complicated model, try to tune the hyperparameter of a decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.DecisionTreeRegressor().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model also requires tuning, but the current API we are using (linear_model.LinearRegression) is relatively weak and lacks the parameters we are looking for. Instead, we will work with elastic nets, and go beyond linear model complexity to build a better linear regression model. We will look at this in detail in the next session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by taking the model beyond linearity. In statistical languages more tuned towards modelling like R, we introduce polynomial features/covariates through a parameter within the model, as such:  \n",
    "\n",
    "`lr = lm(y ~ poly(X, 3))`  \n",
    "\n",
    "However, in the context of sklearn, the `LinearRegression` class solely focuses on optimising a set of regression coefficients for you, and does not look at coefficients. We will need to use modules from `sklearn.preprocessing` to help us develop polynomial features.\n",
    "\n",
    "To start off, develop sets of polynomials features to different degrees. It is up to you to decide what power to raise for the features, but keep it mind that high numbers put additional strain on your machine at an exponential rate, so be mindful of what your machine is capable of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 RFE Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of working with a large quantity of features is by using the Recursive Feature Elimination (RFE) algorithm. The name may provide us with a hint of what it does, but do explain ,with the language for a layperson, what RFE is doing and how it is executed algorithmically. Then, run the code to execute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression on the model. How can we go beyond the final variables remaining in RFE to further improve the performance of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the drawbacks of RFE, and explain them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method to reduce model complexity is through regularisation. Regularisation is the idea of penalising large weights as part of the model fitting process, and forcing the model to trade-off between large weights and model accuracy.\n",
    "\n",
    "In your own words, explain why forcing the model to not adapt large weights can somehow help with feature selection and model fitting in general. How does the algorithm help the model to learn to recognise the best set of weights with a regularisation term?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a L1 regression model through feature selection by regularisation. Tune your model to achieve optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this process for a elastic net model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the differences between each type of regression - in this case, which is a superior model to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of use, build pipelines using `sklearn.pipeline` so that these models can be better consumed later for meta-model ensembling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do RFE and regularisation-based models compare? Think about the strengths and weaknesses of regularisation, as compared to RFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembling is the process of combining prediction models to improve overall performence. In this section, we'll look at various ways this can be done to achieve better resultings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term \"bag\" is the abbreviation for \"bootstrap aggregation\", in which we build a boostrap for a dataset, then train a model for each dataset we produce, after which we aggregate the score. If you are not yet familiar with any of these concepts, do some research and appreciate the process. We will not go into detail here as we already have done that last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your tuned Decision Tree model from a previous section as the base model, implement and tune a model with bagging technique. Compare this result with a random forest model built from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting, as explained earlier this week, uses an aggregation of weak learners to reduce the total variance. It operates on a single model sequentially. At each iteration, it tries to rectify the errors made in the previous iteration.\n",
    "\n",
    "a) Explain the term \"weak learner\".  \n",
    "b) Explain how adaptive boosting (AdaBoost) and gradient boosting (GBM) work and highlight their differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform AdaBoost and Gradient Boosting on Boston, and compare the accuracies. Comment on the performances as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we use an XGBoost (eXtreme Gradient Boosting) model, which outperforms typical boosting models due to its ability to be parallelized AND having the appropriate tunable regularisation and tree parameters. Try reading up the documentation on `xgboost` and tune an `xgboost model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, stacking helps us bring all the models we have done from all the past attempts into one big model. Before this, we have been evaluating models at an individual level. How can we best bring the performance of all these models together, into one even stronger model?\n",
    "\n",
    "One such approach is stacking. Stacking is building a meta-level model that can take the results of each model, and combine them in an appropriate manner to create a even stronger model. Stacking-based meta-models have seen [success on modelling competitions](https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/) in recent years, due to availability of compute power to data scientists.\n",
    "\n",
    "Build a linear regression meta model stacking on top of all the models you've built so far. Report on your accuracy - this is the final accuracy we are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the minimum MSE corresponds to the point where the balance between bias and variance is met. MSE is accessible by us. This is the reason why cross-validation and outsample test methods used in Week 1 can be used not only for validation, but also for us to tune our model complexity. In the following sections, we will explore how we use them to guide model selection, hyperparameter tuning, regularisation and ensemble methods; all to get the best generalisation capability possible (i.e. the balancing act)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! \n",
    "### You have reached the end of our notebook :)\n",
    "#### Now what?\n",
    "If you still have time and you're considering what would be the best use of it, <br>\n",
    "please continue and try your luck with the next (and optional) section of the notebook.<br>\n",
    "Alternatively, if you have yet to completed the previous notebook, or if there are parts you wish to go back to and revisit/revise/tune or read up more about, feel free to do so..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Fireworks.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Other directions (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Try and repeat the notebook's process, only this time use classification models/problem instead of regression.\n",
    "2. Bias-variance is only one means of model profiling we looked into in this notebookt. Try to research and look into  other measures of model profiling, i.e. by vc dimension, induction bias, empirical risk minimisation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
